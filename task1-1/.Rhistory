print("Casino Label Map:")
print(label_map)
# --- Load and Combine Subject Data ---
all_files <- list.files(path = data_dir, pattern = "subject_\\d+\\.csv$", full.names = TRUE)
# Read all CSVs into a list and then combine
all_data_list <- lapply(all_files, read.csv)
all_data <- bind_rows(all_data_list)
# Ensure correct data types
all_data <- all_data %>%
mutate(
subject_id = as.factor(subject_id),
casino = as.factor(casino),
chosen_machine_label = as.character(chosen_machine_label)
)
print("Loaded data summary:")
summary(all_data)
print(head(all_data))
# --- Define the Fitting Function ---
pa <- function(subject_id_factor, all_subj_data, casino_labels_map){
library(dplyr)
library(DEoptim)
# Convert subject_id_factor to character
subj_id <- as.character(subject_id_factor)
cat("Starting processing for subject:", subj_id, "\n")
flush.console()
# Filter data for the current subject
dd <- all_subj_data %>%
filter(as.character(subject_id) == subj_id) # Use factor for filtering dplyr
# Get Unique IDs for the current subject
list_casinos <- unique(as.character(dd$casino))
blocks <- length(list_casinos) # number of blocks is the number of casinos
# Define the negative log-likelihood function
LogL<-function(pp){
counter <- 0
function(pp) {
counter <<- counter + 1
if(counter %% 50 == 0) {
cat("Subject", subj_id, "DEoptim evaluation:", counter, "\n")
flush.console()
}
len1<-pp[1] # alpha plus
len2<-pp[2] # alpha minus
tau<-pp[3] # beta
logl<-0 # initialize log likelihood
for (m in 1:blocks){  ##3 conditions X 2 repeats by the number of pic1
c_id_chr <- list_casinos[m] # current casino ID
# Get data for the current casino
data_real<-dd %>%
filter(casino == c_id_chr) %>%
arrange(visit_in_casino)
# Add a check: warn if there are fewer trials than expected
if(nrow(data_real) < trails_this_casino) {
cat("Warning: subject", subj_id, "casino", c_id_chr, "has", nrow(data_real),
"trials instead of", trails_this_casino, "\n")
flush.console()
}
trails_this_casino <- 24 # number of trials for the current casino
# Initialize value vector
value <- c(0, 0)
# Get the label-to-index map for this casino
current_map <- casino_labels_map[[c_id_chr]]$map
if (is.null(current_map)) {
stop(paste("No map found for casino:", c_id_chr))
}
# Iterate through each trial
for (i in 1:trails_this_casino){
# Map the chosen machine label to the index
chosen_label <- data_real$chosen_machine_label[i]
choose <- current_map[[chosen_label]] # mapped index (1 or 2)
# Get the outcome of the chosen machine
reward1 <- data_real$reward[i] ## chosen option
# Calculate likelihood (softmax)
exp_tau_vals <- exp(tau * value)
v1 <- exp_tau_vals[choose]
vt <- sum(exp_tau_vals)
logl <- logl + log(v1 / vt) ## likelihood function: p=v1/vt
pe1 <- reward1 - value[choose]  ## prediction error
if(pe1>0){
value[choose] <- value[choose]+len1*pe1 ## PE>0
}
if(pe1<0){
value[choose] <- value[choose]+len2*pe1 ## PE<0
}
}
}
res <- -logl
if (!is.finite(res)) {
cat("Non-finite objective function for subject", subj_id, "\n")
flush.console()
res <- 1e10  # assign a high penalty
}
return(res)
}
}
estimates_school = DEoptim(LogL, lower =c(0,0,0), upper=c(1,1,20),control = DEoptim.control(trace = FALSE, NP = 50,itermax = 200))
dd1<-summary(estimates_school)
a<-dd1$optim$bestmem[1]
b<-dd1$optim$bestmem[2]
c<-dd1$optim$bestmem[3]
d<-dd1$optim$bestval
final=c(alpha_plus = a, alpha_minus = b, beta = c, negLogLik = d, subject_id = subj_id)
return(final)
}
list_ID <- unique(all_data$subject_id)
pa(list_ID[1], all_subj_data = all_data, casino_labels_map = label_map)
# Clear workspace
rm(list=ls())
# Load necessary libraries
library(dplyr)
library(DEoptim)
# Set working directory
project_dir <- "/Users/hroyhong/Desktop/code/task1"
setwd(project_dir)
# Read data
data_dir <- file.path(project_dir, "logs")
output_dir <- file.path(project_dir, "analysis", "results") # Create this folder if it doesn't exist
# --- Load Casino Labels ---
casino_labels_file <- file.path(project_dir, "casino_labels.csv")
casino_labels_df <- read.csv(casino_labels_file)
# Create a lookup list for easy mapping: Casino -> list(labels=c('L1','L2'), map=list('L1'=1, 'L2'=2))
label_map <- setNames(lapply(1:nrow(casino_labels_df), function(i) {
labels <- c(as.character(casino_labels_df[i, 2]), as.character(casino_labels_df[i, 3]))
map <- setNames(c(1, 2), labels)
list(labels = labels, map = map)
}), as.character(casino_labels_df$casino))
print("Casino Label Map:")
print(label_map)
# --- Load and Combine Subject Data ---
all_files <- list.files(path = data_dir, pattern = "subject_\\d+\\.csv$", full.names = TRUE)
# Read all CSVs into a list and then combine
all_data_list <- lapply(all_files, read.csv)
all_data <- bind_rows(all_data_list)
# Ensure correct data types
all_data <- all_data %>%
mutate(
subject_id = as.factor(subject_id),
casino = as.factor(casino),
chosen_machine_label = as.character(chosen_machine_label)
)
print("Loaded data summary:")
summary(all_data)
print(head(all_data))
# --- Define the Fitting Function ---
pa <- function(subject_id_factor, all_subj_data, casino_labels_map){
library(dplyr)
library(DEoptim)
# Convert subject_id_factor to character
subj_id <- as.character(subject_id_factor)
cat("Starting processing for subject:", subj_id, "\n")
flush.console()
# Filter data for the current subject
dd <- all_subj_data %>%
filter(as.character(subject_id) == subj_id) # Use factor for filtering dplyr
# Get Unique IDs for the current subject
list_casinos <- unique(as.character(dd$casino))
blocks <- length(list_casinos) # number of blocks is the number of casinos
# Define the negative log-likelihood function
LogL<-function(pp){
counter <- 0
function(pp) {
counter <<- counter + 1
if(counter %% 50 == 0) {
cat("Subject", subj_id, "DEoptim evaluation:", counter, "\n")
flush.console()
}
len1<-pp[1] # alpha plus
len2<-pp[2] # alpha minus
tau<-pp[3] # beta
logl<-0 # initialize log likelihood
for (m in 1:blocks){  ##3 conditions X 2 repeats by the number of pic1
c_id_chr <- list_casinos[m] # current casino ID
# Get data for the current casino
data_real<-dd %>%
filter(casino == c_id_chr) %>%
arrange(visit_in_casino)
# Add a check: warn if there are fewer trials than expected
if(nrow(data_real) < trails_this_casino) {
cat("Warning: subject", subj_id, "casino", c_id_chr, "has", nrow(data_real),
"trials instead of", trails_this_casino, "\n")
flush.console()
}
trails_this_casino <- 24 # number of trials for the current casino
# Initialize value vector
value <- c(0, 0)
# Get the label-to-index map for this casino
current_map <- casino_labels_map[[c_id_chr]]$map
if (is.null(current_map)) {
stop(paste("No map found for casino:", c_id_chr))
}
# Iterate through each trial
for (i in 1:trails_this_casino){
# Map the chosen machine label to the index
chosen_label <- data_real$chosen_machine_label[i]
choose <- current_map[[chosen_label]] # mapped index (1 or 2)
# Get the outcome of the chosen machine
reward1 <- data_real$reward[i] ## chosen option
# Calculate likelihood (softmax)
exp_tau_vals <- exp(tau * value)
v1 <- exp_tau_vals[choose]
vt <- sum(exp_tau_vals)
logl <- logl + log(v1 / vt) ## likelihood function: p=v1/vt
pe1 <- reward1 - value[choose]  ## prediction error
if(pe1>0){
value[choose] <- value[choose]+len1*pe1 ## PE>0
}
if(pe1<0){
value[choose] <- value[choose]+len2*pe1 ## PE<0
}
}
}
res <- -logl
if (!is.finite(res)) {
cat("Non-finite objective function for subject", subj_id, "\n")
flush.console()
res <- 1e10  # assign a high penalty
}
return(res)
}
}
estimates_school = DEoptim(LogL, lower =c(0,0,0), upper=c(1,1,20),control = DEoptim.control(trace = FALSE, NP = 50,itermax = 200))
dd1<-summary(estimates_school)
a<-dd1$optim$bestmem[1]
b<-dd1$optim$bestmem[2]
c<-dd1$optim$bestmem[3]
d<-dd1$optim$bestval
final=c(alpha_plus = a, alpha_minus = b, beta = c, negLogLik = d, subject_id = subj_id)
return(final)
}
list_ID <- unique(all_data$subject_id)
pa(list_ID[1], all_subj_data = all_data, casino_labels_map = label_map)
# Clear workspace
rm(list=ls())
# Load necessary libraries
library(dplyr)
library(DEoptim)
# Set working directory
project_dir <- "/Users/hroyhong/Desktop/code/task1"
setwd(project_dir)
# Read data
data_dir <- file.path(project_dir, "logs")
output_dir <- file.path(project_dir, "analysis", "results") # Create this folder if it doesn't exist
# --- Load Casino Labels ---
casino_labels_file <- file.path(project_dir, "casino_labels.csv")
casino_labels_df <- read.csv(casino_labels_file)
# Create a lookup list for easy mapping: Casino -> list(labels=c('L1','L2'), map=list('L1'=1, 'L2'=2))
label_map <- setNames(lapply(1:nrow(casino_labels_df), function(i) {
labels <- c(as.character(casino_labels_df[i, 2]), as.character(casino_labels_df[i, 3]))
map <- setNames(c(1, 2), labels)
list(labels = labels, map = map)
}), as.character(casino_labels_df$casino))
print("Casino Label Map:")
print(label_map)
# --- Load and Combine Subject Data ---
all_files <- list.files(path = data_dir, pattern = "subject_\\d+\\.csv$", full.names = TRUE)
# Read all CSVs into a list and then combine
all_data_list <- lapply(all_files, read.csv)
all_data <- bind_rows(all_data_list)
# Ensure correct data types
all_data <- all_data %>%
mutate(
subject_id = as.factor(subject_id),
casino = as.factor(casino),
chosen_machine_label = as.character(chosen_machine_label)
)
print("Loaded data summary:")
summary(all_data)
print(head(all_data))
# --- Define the Fitting Function ---
pa <- function(subject_id_factor, all_subj_data, casino_labels_map){
library(dplyr)
library(DEoptim)
# Convert subject_id_factor to character
subj_id <- as.character(subject_id_factor)
cat("Starting processing for subject:", subj_id, "\n")
flush.console()
# Filter data for the current subject
dd <- all_subj_data %>%
filter(as.character(subject_id) == subj_id) # Use factor for filtering dplyr
# Get Unique IDs for the current subject
list_casinos <- unique(as.character(dd$casino))
blocks <- length(list_casinos) # number of blocks is the number of casinos
# Initialize counter outside the objective function
counter <- 0
# Define the negative log-likelihood function directly
negLogLik_func <- function(pp) {
counter <<- counter + 1
if(counter %% 50 == 0) {
cat("Subject", subj_id, "DEoptim evaluation:", counter, "\n")
flush.console()
}
len1<-pp[1] # alpha plus
len2<-pp[2] # alpha minus
tau<-pp[3] # beta
logl<-0 # initialize log likelihood
for (m in 1:blocks){  ##3 conditions X 2 repeats by the number of pic1
c_id_chr <- list_casinos[m] # current casino ID
# Get data for the current casino
data_real<-dd %>%
filter(casino == c_id_chr) %>%
arrange(visit_in_casino)
# Set number of trials for the current casino before the check
trails_this_casino <- 24 # number of trials for the current casino
# Add a check: warn if there are fewer trials than expected
if(nrow(data_real) < trails_this_casino) {
cat("Warning: subject", subj_id, "casino", c_id_chr, "has", nrow(data_real),
"trials instead of", trails_this_casino, "\n")
flush.console()
}
# Initialize value vector
value <- c(0, 0)
# Get the label-to-index map for this casino
current_map <- casino_labels_map[[c_id_chr]]$map
if (is.null(current_map)) {
stop(paste("No map found for casino:", c_id_chr))
}
# Iterate through each trial
for (i in 1:trails_this_casino){
# Map the chosen machine label to the index
chosen_label <- data_real$chosen_machine_label[i]
choose <- current_map[[chosen_label]] # mapped index (1 or 2)
# Get the outcome of the chosen machine
reward1 <- data_real$reward[i] ## chosen option
# Calculate likelihood (softmax)
exp_tau_vals <- exp(tau * value)
v1 <- exp_tau_vals[choose]
vt <- sum(exp_tau_vals)
logl <- logl + log(v1 / vt) ## likelihood function: p=v1/vt
pe1 <- reward1 - value[choose]  ## prediction error
if(pe1>0){
value[choose] <- value[choose]+len1*pe1 ## PE>0
}
if(pe1<0){
value[choose] <- value[choose]+len2*pe1 ## PE<0
}
}
}
res <- -logl
if (!is.finite(res)) {
cat("Non-finite objective function for subject", subj_id, "\n")
flush.console()
res <- 1e10  # assign a high penalty
}
return(res)
}
estimates_school = DEoptim(negLogLik_func, lower =c(0,0,0), upper=c(1,1,20),control = DEoptim.control(trace = FALSE, NP = 50,itermax = 200))
dd1<-summary(estimates_school)
a<-dd1$optim$bestmem[1]
b<-dd1$optim$bestmem[2]
c<-dd1$optim$bestmem[3]
d<-dd1$optim$bestval
final=c(alpha_plus = a, alpha_minus = b, beta = c, negLogLik = d, subject_id = subj_id)
return(final)
}
list_ID <- unique(all_data$subject_id)
pa(list_ID[1], all_subj_data = all_data, casino_labels_map = label_map)
############
library(parallel)
# Get unique subject IDs from the combined data
list_ID <- unique(all_data$subject_id)
# Create a cluster and run the fitting function in parallel
cl <- makeCluster(8)
results <- parLapply(cl, list_ID, pa, all_subj_data = all_data, casino_labels_map = label_map)
stopCluster(cl)
res_df_school <- do.call(rbind, results)
write.table(res_df_school, file = "result/mle_partial_individual_school.csv",
row.names = FALSE, col.names = TRUE, sep = ",")
# Clear workspace
rm(list=ls())
# Clear workspace
rm(list=ls())
# Clear workspace
rm(list=ls())
# Load necessary libraries
library(dplyr)
library(DEoptim)
# Set working directory
project_dir <- "/Users/hroyhong/Desktop/code/task1"
# Clear workspace
rm(list=ls())
# Load necessary libraries
library(dplyr)
library(DEoptim)
# Set working directory
project_dir <- "/Users/hroyhong/Desktop/code/task1"
setwd(project_dir)
# Read data
data_dir <- file.path(project_dir, "logs")
output_dir <- file.path(project_dir, "analysis", "results") # Create this folder if it doesn't exist
# --- Load Casino Labels ---
casino_labels_file <- file.path(project_dir, "casino_labels.csv")
casino_labels_df <- read.csv(casino_labels_file)
# Create a lookup list for easy mapping: Casino -> list(labels=c('L1','L2'), map=list('L1'=1, 'L2'=2))
label_map <- setNames(lapply(1:nrow(casino_labels_df), function(i) {
labels <- c(as.character(casino_labels_df[i, 2]), as.character(casino_labels_df[i, 3]))
map <- setNames(c(1, 2), labels)
list(labels = labels, map = map)
}), as.character(casino_labels_df$casino))
print("Casino Label Map:")
print(label_map)
# --- Load and Combine Subject Data ---
all_files <- list.files(path = data_dir, pattern = "subject_\\d+\\.csv$", full.names = TRUE)
# Read all CSVs into a list and then combine
all_data_list <- lapply(all_files, read.csv)
all_data <- bind_rows(all_data_list)
# Ensure correct data types
all_data <- all_data %>%
mutate(
subject_id = as.factor(subject_id),
casino = as.factor(casino),
chosen_machine_label = as.character(chosen_machine_label)
)
print("Loaded data summary:")
summary(all_data)
print(head(all_data))
# --- Define the Fitting Function ---
pa <- function(subject_id_factor, all_subj_data, casino_labels_map){
library(dplyr)
library(DEoptim)
# Convert subject_id_factor to character
subj_id <- as.character(subject_id_factor)
cat("Starting processing for subject:", subj_id, "\n")
flush.console()
# Filter data for the current subject
dd <- all_subj_data %>%
filter(as.character(subject_id) == subj_id) # Use factor for filtering dplyr
# Get Unique IDs for the current subject
list_casinos <- unique(as.character(dd$casino))
blocks <- length(list_casinos) # number of blocks is the number of casinos
# Initialize counter outside the objective function
counter <- 0
# Define the negative log-likelihood function directly
negLogLik_func <- function(pp) {
counter <<- counter + 1
if(counter %% 50 == 0) {
cat("Subject", subj_id, "DEoptim evaluation:", counter, "\n")
flush.console()
}
len1<-pp[1] # alpha plus
len2<-pp[2] # alpha minus
tau<-pp[3] # beta
logl<-0 # initialize log likelihood
for (m in 1:blocks){  ##3 conditions X 2 repeats by the number of pic1
c_id_chr <- list_casinos[m] # current casino ID
# Get data for the current casino
data_real<-dd %>%
filter(casino == c_id_chr) %>%
arrange(visit_in_casino)
# Set number of trials for the current casino before the check
trails_this_casino <- 24 # number of trials for the current casino
# Add a check: warn if there are fewer trials than expected
if(nrow(data_real) < trails_this_casino) {
cat("Warning: subject", subj_id, "casino", c_id_chr, "has", nrow(data_real),
"trials instead of", trails_this_casino, "\n")
flush.console()
}
# Initialize value vector
value <- c(0, 0)
# Get the label-to-index map for this casino
current_map <- casino_labels_map[[c_id_chr]]$map
if (is.null(current_map)) {
stop(paste("No map found for casino:", c_id_chr))
}
# Iterate through each trial
for (i in 1:trails_this_casino){
# Map the chosen machine label to the index
chosen_label <- data_real$chosen_machine_label[i]
choose <- current_map[[chosen_label]] # mapped index (1 or 2)
# Get the outcome of the chosen machine
reward1 <- data_real$reward[i] ## chosen option
# Calculate likelihood (softmax)
exp_tau_vals <- exp(tau * value)
v1 <- exp_tau_vals[choose]
vt <- sum(exp_tau_vals)
logl <- logl + log(v1 / vt) ## likelihood function: p=v1/vt
pe1 <- reward1 - value[choose]  ## prediction error
if(pe1>0){
value[choose] <- value[choose]+len1*pe1 ## PE>0
}
if(pe1<0){
value[choose] <- value[choose]+len2*pe1 ## PE<0
}
}
}
res <- -logl
if (!is.finite(res)) {
cat("Non-finite objective function for subject", subj_id, "\n")
flush.console()
res <- 1e10  # assign a high penalty
}
return(res)
}
estimates_school = DEoptim(negLogLik_func, lower =c(0,0,0), upper=c(1,1,20),control = DEoptim.control(trace = FALSE, NP = 50,itermax = 200))
dd1<-summary(estimates_school)
a<-dd1$optim$bestmem[1]
b<-dd1$optim$bestmem[2]
c<-dd1$optim$bestmem[3]
d<-dd1$optim$bestval
final=c(alpha_plus = a, alpha_minus = b, beta = c, negLogLik = d, subject_id = subj_id)
return(final)
}
list_ID <- unique(all_data$subject_id)
############
library(parallel)
# Get unique subject IDs from the combined data
list_ID <- unique(all_data$subject_id)
# Create a cluster and run the fitting function in parallel
cl <- makeCluster(8)
results <- parLapply(cl, list_ID, pa, all_subj_data = all_data, casino_labels_map = label_map)
pa(list_ID[1], all_subj_data = all_data, casino_labels_map = label_map)
pa(list_ID[2], all_subj_data = all_data, casino_labels_map = label_map)
pa(list_ID[3], all_subj_data = all_data, casino_labels_map = label_map)
pa(list_ID[4], all_subj_data = all_data, casino_labels_map = label_map)

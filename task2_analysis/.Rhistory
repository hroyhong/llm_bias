}
if (pe_unchosen < 0) {
value2[unchosen_index] <- value2[unchosen_index] + alpha_neg_u * pe_unchosen # Unchosen PE < 0
}
}
if (casino==3){
v1=exp(tau*value3[choose])
vt<-exp(tau*value3[1])+exp(tau*value3[2])
logl<-logl+log(v1/vt) ##likelihood function:p=v1/vt
pe1=reward1-value3[choose]  ## chosen option PE
if(pe1>0){
value3[choose]<-value3[choose] + alpha_pos_c * pe1 ## Chosen PE > 0
}
if(pe1<0){
value3[choose]<-value3[choose] + alpha_neg_c * pe1 ## Chosen PE < 0
}
# --- Add this for unchosen update ---
unchosen_index <- 3 - choose # Get index of the unchosen option (1 or 2)
reward_unchosen <- dd$counterfactual_reward[i] # Use the correct column name
pe_unchosen <- reward_unchosen - value3[unchosen_index] # PE for unchosen
if (pe_unchosen > 0) {
value3[unchosen_index] <- value3[unchosen_index] + alpha_pos_u * pe_unchosen # Unchosen PE > 0
}
if (pe_unchosen < 0) {
value3[unchosen_index] <- value3[unchosen_index] + alpha_neg_u * pe_unchosen # Unchosen PE < 0
}
}
}
logl<-(-logl)
return(logl)
}
estimates_school = DEoptim(LogL,lower =c(0,0,0,0,0),upper=c(1,1,1,1,20),control = DEoptim.control(trace = FALSE,NP = 80,itermax = 250))
dd1<-summary(estimates_school)
a<-dd1$optim$bestmem[1] # alpha_pos_c
b<-dd1$optim$bestmem[2] # alpha_neg_c
c<-dd1$optim$bestmem[3] # alpha_pos_u
d<-dd1$optim$bestmem[4] # alpha_neg_u
e<-dd1$optim$bestmem[5] # tau
f<-dd1$optim$bestval   # LogLikelihood
g<-list_ID[li]         # Subject ID
final=c(a,b,c,d,e,f,g)
return(final)
}
##################
library(parallel)
library(snow)
library(SnowballC)
list_ID<-unique(dat$subj)
cl <- makeCluster(8)
results<-parLapply(cl,1:length(list_ID),pa)
res<-do.call('rbind',results)
write.table(res,"/Users/hroyhong/Desktop/llm0412/task1/result/parallel_mle_result_p_comp.csv",row.names=FALSE,col.names=TRUE,sep=",")
rm(list=ls())
library(dplyr)
library(DEoptim)
dat<-read.csv('/Users/hroyhong/Desktop/llm0412/task1/data/combined_p_comp.csv')
pa<-function(li){
library(dplyr)
library(DEoptim)
dat<-read.csv('/Users/hroyhong/Desktop/llm0412/task1/data/combined_p_comp.csv')
list_ID<-unique(dat$subj)
subj<-length(unique(dat$subj))
dd <- dat[dat$subj == list_ID[li] & (dat$casino == 2 | dat$casino == 3), ]
LogL<-function(pp){
# With this:
alpha_pos_c <- pp[1] # Alpha for Positive PE Chosen
alpha_neg_c <- pp[2] # Alpha for Negative PE Chosen
alpha_pos_u <- pp[3] # Alpha for Positive PE Unchosen
alpha_neg_u <- pp[4] # Alpha for Negative PE Unchosen
tau <- pp[5]         # Inverse temperature
logl<-0
value2<-c(0,0)
value3<-c(0,0)
for (i in 1:nrow(dd)){
choose=dd$decision[i] ## 1.left,2.right
reward1=dd$reward[i] ## chosen option
casino=dd$casino[i]
if (casino==2){
v1=exp(tau*value2[choose])
vt<-exp(tau*value2[1])+exp(tau*value2[2])
logl<-logl+log(v1/vt) ##likelihood function:p=v1/vt
pe1=reward1-value2[choose]  ## chosen option PE
if(pe1>0){
value2[choose]<-value2[choose] + alpha_pos_c * pe1 ## Chosen PE > 0
}
if(pe1<0){
value2[choose]<-value2[choose] + alpha_neg_c * pe1 ## Chosen PE < 0
}
unchosen_index <- 3 - choose # Get index of the unchosen option (1 or 2)
reward_unchosen <- dd$counterfactual_reward[i] # Use the correct column name
pe_unchosen <- reward_unchosen - value2[unchosen_index] # PE for unchosen
if (pe_unchosen > 0) {
value2[unchosen_index] <- value2[unchosen_index] + alpha_pos_u * pe_unchosen # Unchosen PE > 0
}
if (pe_unchosen < 0) {
value2[unchosen_index] <- value2[unchosen_index] + alpha_neg_u * pe_unchosen # Unchosen PE < 0
}
}
if (casino==3){
v1=exp(tau*value3[choose])
vt<-exp(tau*value3[1])+exp(tau*value3[2])
logl<-logl+log(v1/vt) ##likelihood function:p=v1/vt
pe1=reward1-value3[choose]  ## chosen option PE
if(pe1>0){
value3[choose]<-value3[choose] + alpha_pos_c * pe1 ## Chosen PE > 0
}
if(pe1<0){
value3[choose]<-value3[choose] + alpha_neg_c * pe1 ## Chosen PE < 0
}
# --- Add this for unchosen update ---
unchosen_index <- 3 - choose # Get index of the unchosen option (1 or 2)
reward_unchosen <- dd$counterfactual_reward[i] # Use the correct column name
pe_unchosen <- reward_unchosen - value3[unchosen_index] # PE for unchosen
if (pe_unchosen > 0) {
value3[unchosen_index] <- value3[unchosen_index] + alpha_pos_u * pe_unchosen # Unchosen PE > 0
}
if (pe_unchosen < 0) {
value3[unchosen_index] <- value3[unchosen_index] + alpha_neg_u * pe_unchosen # Unchosen PE < 0
}
}
}
logl<-(-logl)
return(logl)
}
estimates_school = DEoptim(LogL,lower =c(0,0,0,0,0),upper=c(1,1,1,1,40),control = DEoptim.control(trace = FALSE,NP = 80,itermax = 250))
dd1<-summary(estimates_school)
a<-dd1$optim$bestmem[1] # alpha_pos_c
b<-dd1$optim$bestmem[2] # alpha_neg_c
c<-dd1$optim$bestmem[3] # alpha_pos_u
d<-dd1$optim$bestmem[4] # alpha_neg_u
e<-dd1$optim$bestmem[5] # tau
f<-dd1$optim$bestval   # LogLikelihood
g<-list_ID[li]         # Subject ID
final=c(a,b,c,d,e,f,g)
return(final)
}
##################
library(parallel)
library(snow)
library(SnowballC)
list_ID<-unique(dat$subj)
cl <- makeCluster(8)
results<-parLapply(cl,1:length(list_ID),pa)
res<-do.call('rbind',results)
write.table(res,"/Users/hroyhong/Desktop/llm0412/task1/result/parallel_mle_result_p_comp.csv",row.names=FALSE,col.names=TRUE,sep=",")
# plot_llm_params.R
# -----------------
# Load required libraries
library(ggplot2)
# 1. Read CSV output from the MLE fitting
#    Make sure the path matches where your CSV file is actually saved.
df <- read.csv("/Users/hroyhong/Desktop/llm0412/task1/result/parallel_mle_result_p_comp.csv.csv", header = TRUE)
# plot_llm_params.R
# -----------------
# Load required libraries
library(ggplot2)
# 1. Read CSV output from the MLE fitting
#    Make sure the path matches where your CSV file is actually saved.
df <- read.csv("/Users/hroyhong/Desktop/llm0412/task1/result/parallel_mle_result_p_comp.csv.csv", header = TRUE)
# plot_llm_params.R
# -----------------
# Load required libraries
library(ggplot2)
# 1. Read CSV output from the MLE fitting
#    Make sure the path matches where your CSV file is actually saved.
df <- read.csv("/Users/hroyhong/Desktop/llm0412/task1/result/parallel_mle_result_p_comp.csv.csv", header = TRUE)
getwd()
setwd("")
setwd("..")
# plot_llm_params.R
# -----------------
# Load required libraries
library(ggplot2)
# 1. Read CSV output from the MLE fitting
#    Make sure the path matches where your CSV file is actually saved.
df <- read.csv("/Users/hroyhong/Desktop/llm0412/task1/result/parallel_mle_result_p_comp.csv.csv", header = TRUE)
# plot_llm_params.R
# -----------------
# Load required libraries
library(ggplot2)
# 1. Read CSV output from the MLE fitting
#    Make sure the path matches where your CSV file is actually saved.
df <- read.csv("/Users/hroyhong/Desktop/llm0412/task1/result/parallel_mle_result_p_comp.csv.csv", header = TRUE)
# plot_llm_params.R
# -----------------
# Load required libraries
library(ggplot2)
# 1. Read CSV output from the MLE fitting
#    Make sure the path matches where your CSV file is actually saved.
df <- read.csv("/Users/hroyhong/Desktop/llm0412/task1/result/parallel_mle_result_p_comp.csv", header = TRUE)
head(df)
summary(df)
# If your CSV does not already have clear column names, rename them here:
#   a = alpha_plus, b = alpha_minus, c = tau, d = bestval, e = subj
# If your existing CSV already has good names, adjust accordingly.
colnames(df) <- c("alpha_plus", "alpha_minus", "tau", "bestval", "subj")
# 2. Compute means and standard errors across all subjects
alpha_plus_mean  <- mean(df$alpha_plus)
alpha_plus_se    <- sd(df$alpha_plus) / sqrt(nrow(df))
alpha_minus_mean <- mean(df$alpha_minus)
alpha_minus_se   <- sd(df$alpha_minus) / sqrt(nrow(df))
# 3. Organize data for plotting
plot_df <- data.frame(
Condition = factor(c("alpha^+", "alpha^-"), levels = c("alpha^+", "alpha^-")),
Mean      = c(alpha_plus_mean, alpha_minus_mean),
SE        = c(alpha_plus_se, alpha_minus_se)
)
# 4. Create the bar plot with error bars
p <- ggplot(plot_df, aes(x = Condition, y = Mean, fill = Condition)) +
geom_bar(stat = "identity", width = 0.6) +
geom_errorbar(aes(ymin = Mean - SE, ymax = Mean + SE), width = 0.2) +
scale_fill_manual(values = c("orchid4", "orchid4")) +
labs(x = NULL, y = "Learning rate") +
theme_classic() +
theme(legend.position = "none") +
# Use expressions to get the superscript plus/minus in the axis labels
scale_x_discrete(labels = c(expression(alpha^"+"), expression(alpha^"-")))
# 5. Print the plot to your R graphics window
print(p)
# (Optional) Save the plot to a file
ggsave("/Users/hroyhong/Desktop/llm0412/task1/result/llm_learning_rates_p.png", plot = p, width = 4, height = 4, dpi = 300)
# plot_llm_params_chosen_unchosen.R
# ---------------------------------
# Load required libraries
library(ggplot2)
library(dplyr) # Using dplyr for easier calculation
# 1. Read CSV output from the *new* MLE fitting (5 parameters)
#    Make sure the path matches where your CSV file is actually saved.
#    IMPORTANT: Ensure this is the file generated AFTER modifying the MLE script for 5 parameters.
file_path <- "/Users/hroyhong/Desktop/llm0412/task1/result/parallel_mle_result_p_comp.csv"
if (!file.exists(file_path)) {
stop("Error: CSV file not found at specified path: ", file_path)
}
df <- read.csv(file_path, header = TRUE)
# Check if the dataframe looks reasonable (should have more columns than before)
print("Original Column Names:")
print(colnames(df))
print("First few rows:")
print(head(df))
print("Summary:")
print(summary(df))
# Check if the number of columns seems correct for 5 parameters + logL + subjID
# Expecting potentially 7 or more columns depending on how write.table formatted empty ones.
# We will select the first 7 assuming they are the relevant ones.
if (ncol(df) < 7) {
stop("Error: CSV file does not appear to have enough columns for the 5-parameter model results.")
}
df <- df[, 1:7] # Select the first 7 columns
# 2. Rename columns to be descriptive for the 5-parameter model
#    **CRITICAL STEP**: Adjust this order if your MLE script saved them differently.
colnames(df) <- c("alpha_pos_c", "alpha_neg_c", "alpha_pos_u", "alpha_neg_u", "tau", "bestval", "subj")
print("Renamed Columns Head:")
print(head(df))
# 3. Calculate means and standard errors for all four learning rates
#    Using dplyr for clarity
summary_stats <- df %>%
summarise(
alpha_pos_c_mean = mean(alpha_pos_c, na.rm = TRUE),
alpha_pos_c_se   = sd(alpha_pos_c, na.rm = TRUE) / sqrt(n()),
alpha_neg_c_mean = mean(alpha_neg_c, na.rm = TRUE),
alpha_neg_c_se   = sd(alpha_neg_c, na.rm = TRUE) / sqrt(n()),
alpha_pos_u_mean = mean(alpha_pos_u, na.rm = TRUE),
alpha_pos_u_se   = sd(alpha_pos_u, na.rm = TRUE) / sqrt(n()),
alpha_neg_u_mean = mean(alpha_neg_u, na.rm = TRUE),
alpha_neg_u_se   = sd(alpha_neg_u, na.rm = TRUE) / sqrt(n())
)
# 4. Organize data for plotting (for the example image style)
# Create a single factor representing the four distinct conditions in the desired order
plot_df <- data.frame(
# Define the condition names and ensure they are ordered correctly for the plot
Condition = factor(
c("Chosen_Alpha_Pos", "Chosen_Alpha_Neg", "Unchosen_Alpha_Pos", "Unchosen_Alpha_Neg"),
levels = c("Chosen_Alpha_Pos", "Chosen_Alpha_Neg", "Unchosen_Alpha_Pos", "Unchosen_Alpha_Neg")
),
# Assign the corresponding means calculated earlier
Mean      = c(summary_stats$alpha_pos_c_mean, summary_stats$alpha_neg_c_mean,
summary_stats$alpha_pos_u_mean, summary_stats$alpha_neg_u_mean),
# Assign the corresponding standard errors
SE        = c(summary_stats$alpha_pos_c_se, summary_stats$alpha_neg_c_se,
summary_stats$alpha_pos_u_se, summary_stats$alpha_neg_u_se)
)
print("Data frame for plotting (New Structure):")
print(plot_df)
# 5. Create the bar plot like the example image
# Choose a single color similar to the example (adjust color name as needed)
plot_color <- "palevioletred3"
p <- ggplot(plot_df, aes(x = Condition, y = Mean)) + # Base mapping: x and y
geom_bar(stat = "identity", fill = plot_color, width = 0.7) + # Bars with fixed color
geom_errorbar(aes(ymin = Mean - SE, ymax = Mean + SE), width = 0.25) + # Error bars
# Set the specific labels for the x-axis ticks corresponding to the Condition levels
scale_x_discrete(labels = c(
"Chosen_Alpha_Pos"   = expression(alpha^"+"),
"Chosen_Alpha_Neg"   = expression(alpha^"-"),
"Unchosen_Alpha_Pos" = expression(alpha^"+"),
"Unchosen_Alpha_Neg" = expression(alpha^"-")
)) +
labs(x = NULL, y = "Learning rate") + # Set y-axis label, remove x-axis label text
theme_classic(base_size = 16) + # Use classic theme, slightly larger text
theme(
axis.title.x = element_blank(),  # Remove space for x-axis title
axis.text.x = element_text(size=14), # Increase size of alpha labels
axis.ticks.x = element_blank()   # Remove x-axis ticks if desired (like example)
)
# Optional: Add a title if desired
# Note: Adding the overarching "Chosen" / "Unchosen" labels with brackets below the axis
# requires more advanced techniques like annotations or patchwork, which go beyond
# minimal changes to the standard ggplot call. This code produces the bars and alpha labels.
print(p)
rm(list=ls())
library(dplyr)
file<-list.files("/Users/hroyhong/Desktop/llm0412/task1/data/logs_reward_complete//")
path<-'/Users/hroyhong/Desktop/llm0412/task1/data/logs_reward_complete//'
###combined data
final<-NULL
kk=0
for (i in 1:length(file)){
kk=kk+1
dd<-paste(path,'/',file[i],sep='')
data<-read.csv(dd)
data<-data%>%
mutate(subj=kk)
final<-rbind(final,data)
}
unique(final$subject_id)
###
final<-final%>%
mutate(decision = case_when(
chosen_machine_label %in% c("Z", "M", "Q", "G") ~ 1,
TRUE ~ 2
))
# Write the final dataset to a CSV file
write.csv(final, "/Users/hroyhong/Desktop/llm0412/task1/data/combined_r_comp.csv", row.names = FALSE)
rm(list=ls())
library(dplyr)
library(DEoptim)
dat<-read.csv('/Users/hroyhong/Desktop/llm0412/task1/data/combined_r_comp.csv')
pa<-function(li){
library(dplyr)
library(DEoptim)
dat<-read.csv('/Users/hroyhong/Desktop/llm0412/task1/data/combined_r_comp.csv')
list_ID<-unique(dat$subj)
subj<-length(unique(dat$subj))
dd <- dat[dat$subj == list_ID[li] & (dat$casino == 2 | dat$casino == 3), ]
LogL<-function(pp){
# With this:
alpha_pos_c <- pp[1] # Alpha for Positive PE Chosen
alpha_neg_c <- pp[2] # Alpha for Negative PE Chosen
alpha_pos_u <- pp[3] # Alpha for Positive PE Unchosen
alpha_neg_u <- pp[4] # Alpha for Negative PE Unchosen
tau <- pp[5]         # Inverse temperature
logl<-0
value2<-c(0,0)
value3<-c(0,0)
for (i in 1:nrow(dd)){
choose=dd$decision[i] ## 1.left,2.right
reward1=dd$reward[i] ## chosen option
casino=dd$casino[i]
if (casino==2){
v1=exp(tau*value2[choose])
vt<-exp(tau*value2[1])+exp(tau*value2[2])
logl<-logl+log(v1/vt) ##likelihood function:p=v1/vt
pe1=reward1-value2[choose]  ## chosen option PE
if(pe1>0){
value2[choose]<-value2[choose] + alpha_pos_c * pe1 ## Chosen PE > 0
}
if(pe1<0){
value2[choose]<-value2[choose] + alpha_neg_c * pe1 ## Chosen PE < 0
}
unchosen_index <- 3 - choose # Get index of the unchosen option (1 or 2)
reward_unchosen <- dd$counterfactual_reward[i] # Use the correct column name
pe_unchosen <- reward_unchosen - value2[unchosen_index] # PE for unchosen
if (pe_unchosen > 0) {
value2[unchosen_index] <- value2[unchosen_index] + alpha_pos_u * pe_unchosen # Unchosen PE > 0
}
if (pe_unchosen < 0) {
value2[unchosen_index] <- value2[unchosen_index] + alpha_neg_u * pe_unchosen # Unchosen PE < 0
}
}
if (casino==3){
v1=exp(tau*value3[choose])
vt<-exp(tau*value3[1])+exp(tau*value3[2])
logl<-logl+log(v1/vt) ##likelihood function:p=v1/vt
pe1=reward1-value3[choose]  ## chosen option PE
if(pe1>0){
value3[choose]<-value3[choose] + alpha_pos_c * pe1 ## Chosen PE > 0
}
if(pe1<0){
value3[choose]<-value3[choose] + alpha_neg_c * pe1 ## Chosen PE < 0
}
# --- Add this for unchosen update ---
unchosen_index <- 3 - choose # Get index of the unchosen option (1 or 2)
reward_unchosen <- dd$counterfactual_reward[i] # Use the correct column name
pe_unchosen <- reward_unchosen - value3[unchosen_index] # PE for unchosen
if (pe_unchosen > 0) {
value3[unchosen_index] <- value3[unchosen_index] + alpha_pos_u * pe_unchosen # Unchosen PE > 0
}
if (pe_unchosen < 0) {
value3[unchosen_index] <- value3[unchosen_index] + alpha_neg_u * pe_unchosen # Unchosen PE < 0
}
}
}
logl<-(-logl)
return(logl)
}
estimates_school = DEoptim(LogL,lower =c(0,0,0,0,0),upper=c(1,1,1,1,40),control = DEoptim.control(trace = FALSE,NP = 80,itermax = 250))
dd1<-summary(estimates_school)
a<-dd1$optim$bestmem[1] # alpha_pos_c
b<-dd1$optim$bestmem[2] # alpha_neg_c
c<-dd1$optim$bestmem[3] # alpha_pos_u
d<-dd1$optim$bestmem[4] # alpha_neg_u
e<-dd1$optim$bestmem[5] # tau
f<-dd1$optim$bestval   # LogLikelihood
g<-list_ID[li]         # Subject ID
final=c(a,b,c,d,e,f,g)
return(final)
}
##################
library(parallel)
library(snow)
library(SnowballC)
list_ID<-unique(dat$subj)
cl <- makeCluster(8)
results<-parLapply(cl,1:length(list_ID),pa)
res<-do.call('rbind',results)
write.table(res,"/Users/hroyhong/Desktop/llm0412/task1/result/parallel_mle_result_r_comp.csv",row.names=FALSE,col.names=TRUE,sep=",")
# plot_llm_params_chosen_unchosen.R
# ---------------------------------
# Load required libraries
library(ggplot2)
library(dplyr) # Using dplyr for easier calculation
# 1. Read CSV output from the *new* MLE fitting (5 parameters)
#    Make sure the path matches where your CSV file is actually saved.
#    IMPORTANT: Ensure this is the file generated AFTER modifying the MLE script for 5 parameters.
file_path <- "/Users/hroyhong/Desktop/llm0412/task1/result/parallel_mle_result_r_comp.csv"
if (!file.exists(file_path)) {
stop("Error: CSV file not found at specified path: ", file_path)
}
df <- read.csv(file_path, header = TRUE)
# Check if the dataframe looks reasonable (should have more columns than before)
print("Original Column Names:")
print(colnames(df))
print("First few rows:")
print(head(df))
print("Summary:")
print(summary(df))
# Check if the number of columns seems correct for 5 parameters + logL + subjID
# Expecting potentially 7 or more columns depending on how write.table formatted empty ones.
# We will select the first 7 assuming they are the relevant ones.
if (ncol(df) < 7) {
stop("Error: CSV file does not appear to have enough columns for the 5-parameter model results.")
}
df <- df[, 1:7] # Select the first 7 columns
# 2. Rename columns to be descriptive for the 5-parameter model
#    **CRITICAL STEP**: Adjust this order if your MLE script saved them differently.
colnames(df) <- c("alpha_pos_c", "alpha_neg_c", "alpha_pos_u", "alpha_neg_u", "tau", "bestval", "subj")
print("Renamed Columns Head:")
print(head(df))
# 3. Calculate means and standard errors for all four learning rates
#    Using dplyr for clarity
summary_stats <- df %>%
summarise(
alpha_pos_c_mean = mean(alpha_pos_c, na.rm = TRUE),
alpha_pos_c_se   = sd(alpha_pos_c, na.rm = TRUE) / sqrt(n()),
alpha_neg_c_mean = mean(alpha_neg_c, na.rm = TRUE),
alpha_neg_c_se   = sd(alpha_neg_c, na.rm = TRUE) / sqrt(n()),
alpha_pos_u_mean = mean(alpha_pos_u, na.rm = TRUE),
alpha_pos_u_se   = sd(alpha_pos_u, na.rm = TRUE) / sqrt(n()),
alpha_neg_u_mean = mean(alpha_neg_u, na.rm = TRUE),
alpha_neg_u_se   = sd(alpha_neg_u, na.rm = TRUE) / sqrt(n())
)
# 4. Organize data for plotting (for the example image style)
# Create a single factor representing the four distinct conditions in the desired order
plot_df <- data.frame(
# Define the condition names and ensure they are ordered correctly for the plot
Condition = factor(
c("Chosen_Alpha_Pos", "Chosen_Alpha_Neg", "Unchosen_Alpha_Pos", "Unchosen_Alpha_Neg"),
levels = c("Chosen_Alpha_Pos", "Chosen_Alpha_Neg", "Unchosen_Alpha_Pos", "Unchosen_Alpha_Neg")
),
# Assign the corresponding means calculated earlier
Mean      = c(summary_stats$alpha_pos_c_mean, summary_stats$alpha_neg_c_mean,
summary_stats$alpha_pos_u_mean, summary_stats$alpha_neg_u_mean),
# Assign the corresponding standard errors
SE        = c(summary_stats$alpha_pos_c_se, summary_stats$alpha_neg_c_se,
summary_stats$alpha_pos_u_se, summary_stats$alpha_neg_u_se)
)
print("Data frame for plotting (New Structure):")
print(plot_df)
# 5. Create the bar plot like the example image
# Choose a single color similar to the example (adjust color name as needed)
plot_color <- "palevioletred3"
p <- ggplot(plot_df, aes(x = Condition, y = Mean)) + # Base mapping: x and y
geom_bar(stat = "identity", fill = plot_color, width = 0.7) + # Bars with fixed color
geom_errorbar(aes(ymin = Mean - SE, ymax = Mean + SE), width = 0.25) + # Error bars
# Set the specific labels for the x-axis ticks corresponding to the Condition levels
scale_x_discrete(labels = c(
"Chosen_Alpha_Pos"   = expression(alpha^"+"),
"Chosen_Alpha_Neg"   = expression(alpha^"-"),
"Unchosen_Alpha_Pos" = expression(alpha^"+"),
"Unchosen_Alpha_Neg" = expression(alpha^"-")
)) +
labs(x = NULL, y = "Learning rate") + # Set y-axis label, remove x-axis label text
theme_classic(base_size = 16) + # Use classic theme, slightly larger text
theme(
axis.title.x = element_blank(),  # Remove space for x-axis title
axis.text.x = element_text(size=14), # Increase size of alpha labels
axis.ticks.x = element_blank()   # Remove x-axis ticks if desired (like example)
)
# Optional: Add a title if desired
# Note: Adding the overarching "Chosen" / "Unchosen" labels with brackets below the axis
# requires more advanced techniques like annotations or patchwork, which go beyond
# minimal changes to the standard ggplot call. This code produces the bars and alpha labels.
print(p)
